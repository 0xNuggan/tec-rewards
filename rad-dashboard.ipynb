{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-image",
   "metadata": {},
   "source": [
    "# Rewards Analytics and Distribution Dashboard\n",
    "This goal of this notebook is to offer an easy way to process the outputs of the praise and sourcecred reward systems, perform an analysis of the results and calculate the token reward distribution. It uses mock data and should be considered a work-in-progress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-cheat",
   "metadata": {},
   "source": [
    "### Imports\n",
    "First, we import the relevant libraries, get the Data and set how many tokens we want to distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-unemployment",
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import analytics_toolbox as tb\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "fc_praise = FileChooser('./')\n",
    "fc_sourcecred = FileChooser('./')\n",
    "fc_rewardboard = FileChooser('./')\n",
    "\n",
    "print(\"== Please choose the Praise CSV file == \")\n",
    "display(fc_praise)\n",
    "print(\"== Please choose the Sourcecred CSV file == \")\n",
    "display(fc_sourcecred)\n",
    "print(\"== Please choose the Rewardboard address list CSV file == \")\n",
    "display(fc_rewardboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f6d12",
   "metadata": {},
   "source": [
    "Now that we have selected the files, we can import them for processing. We can also set the total amount of tokens we want to distribute this period. We also set the name we want our output file to have.\n",
    "\n",
    "Tip: Now that the file paths are set, you can safely click on \"Cell > Run all below\" from here on the menu bar to execute everything :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-encyclopedia",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Parameters\n",
    "\n",
    "Set the total amount of tokens we want to distribute this period. We also set the name we want our output file to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-monday",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE = 1950\n",
    "#NUMBER_OF_SOURCECRED_REWARD_TOKENS_TO_DISTRIBUTE = 1950\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS = 500\n",
    "NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD = 100\n",
    "NUMBER_OF_QUANTIFIERES_PER_PRAISE = 3\n",
    "\n",
    "OUTPUT_FILENAME = \"rewards_round_01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-darwin",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "PRAISE_DATA_PATH = fc_praise.selected\n",
    "SOURCECRED_DATA_PATH = fc_sourcecred.selected\n",
    "REWARD_BOARD_ADDRESSES_PATH = fc_rewardboard.selected\n",
    "\n",
    "praise_data = pd.read_csv(PRAISE_DATA_PATH)\n",
    "sourcecred_data = pd.read_csv(SOURCECRED_DATA_PATH)\n",
    "rewardboard_addresses = pd.read_csv(REWARD_BOARD_ADDRESSES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-sussex",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-organizer",
   "metadata": {},
   "source": [
    "## Reward allocation\n",
    "\n",
    "### Praise\n",
    "\n",
    "This method allocates the praise rewards in a very straightforward way: It adds the value of all dished praised together, and then assigns to each user their % of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-rotation",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_praise_rewards(praiseData, tokensToDistribute):\n",
    "    #we discard all we don't need and and calculate the % worth of each praise\n",
    "    #slimData = praiseData[['FROM USER ACCOUNT', 'TO USER ACCOUNT', 'FINAL QUANT']].copy()\n",
    "    totalPraisePoints = praiseData['FINAL QUANT'].sum()\n",
    "\n",
    "    praiseData['PERCENTAGE'] = praiseData['FINAL QUANT']/totalPraisePoints\n",
    "    praiseData['TOKEN TO RECEIVE'] = praiseData['PERCENTAGE'] * tokensToDistribute\n",
    "    return praiseData\n",
    "\n",
    "praise_distribution = calc_praise_rewards(praise_data.copy(), NUMBER_OF_PRAISE_REWARD_TOKENS_TO_DISTRIBUTE)\n",
    "praise_distribution.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-trash",
   "metadata": {},
   "source": [
    "### SourceCred\n",
    "For now Sourcecred does the distribution independently, but if this changed we would calculate the rewards in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-bacteria",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_sourcecred_rewards(sourcecredData, tokensToDistribute):\n",
    "    #we discard all we don't need and and calculate the % worth of each praise\n",
    "    slimData = sourcecredData[['IDENTITY', 'AMOUNT']].copy()\n",
    "    totalGrainPoints = slimData['AMOUNT'].sum()\n",
    "\n",
    "    slimData['PERCENTAGE'] = slimData['AMOUNT']/totalGrainPoints\n",
    "    slimData['TOKEN TO RECEIVE'] = slimData['PERCENTAGE'] * tokensToDistribute\n",
    "    return slimData\n",
    "\n",
    "#sourcecred_distribution = calc_sourcecred_rewards(sourcecred_data.copy(), NUMBER_OF_SOURCECRED_REWARD_TOKENS_TO_DISTRIBUTE)\n",
    "sourcecred_distribution = sourcecred_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-boutique",
   "metadata": {},
   "source": [
    "## Preparing and combining the Datasets\n",
    "\n",
    "Now that we have both distributions, we can combine them into one table.\n",
    "But before that, we need to prepare the data and clean it a bit. We also use the chance to generate a table which shows us how much praise each user received. We'll use it later in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-indonesia",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -removes the '#' and following from discord names\n",
    "#  -Some renaming and dropping \n",
    "def prepare_praise(praise_data):\n",
    "\n",
    "    #praise_data['TO USER ACCOUNT'] = (praise_data['TO USER ACCOUNT'].str.split('#', 1, expand=False).str[0]).str.lower()\n",
    "    \n",
    "    praise_data.rename(columns = {'TO USER ACCOUNT':'USER IDENTITY'}, inplace = True)\n",
    "    praise_data.rename(columns = {'TO ETH ADDRESS':'USER ADDRESS'}, inplace = True)\n",
    "    praise_data['USER ADDRESS'].fillna('MISSING USER ADDRESS', inplace=True)\n",
    "    \n",
    "    processed_praise = praise_data[['USER IDENTITY', 'USER ADDRESS', 'PERCENTAGE', 'TOKEN TO RECEIVE']]\n",
    "    praise_by_user = praise_data[['USER IDENTITY', 'USER ADDRESS', 'FINAL QUANT', 'PERCENTAGE', 'TOKEN TO RECEIVE']].copy().groupby(['USER IDENTITY', 'USER ADDRESS']).agg('sum').reset_index()\n",
    "    \n",
    "    return processed_praise, praise_by_user\n",
    "\n",
    "#General Helper func. Puts all the \"processing we probably won't need to do later or do differently\" in one place\n",
    "#  -Some renaming and dropping \n",
    "#  -changing percentages from 0 - 100 to 0.00-1.00\n",
    "def prepare_sourcecred(sourcecred_data):\n",
    "    \n",
    "    sourcecred_data.rename(columns = {'%':'PERCENTAGE SOURCECRED'}, inplace = True)\n",
    "    sourcecred_data.rename(columns = {'IDENTITY' : 'USER ADDRESS'}, inplace = True)\n",
    "    \n",
    "    sourcecred_data = sourcecred_data[['USER ADDRESS', 'PERCENTAGE SOURCECRED', 'TOKEN TO RECEIVE']]\n",
    "    \n",
    "    return sourcecred_data\n",
    "\n",
    "\n",
    "processed_praise, praise_by_user = prepare_praise(praise_distribution.copy())\n",
    "processed_sourcecred = prepare_sourcecred(sourcecred_distribution.copy())\n",
    "praise_by_user.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-crime",
   "metadata": {},
   "source": [
    "Let's also create a table which will let us focus on the quantifiers. It will show us what value each quantifier gave to each single praise item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-premiere",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def data_by_quantifier(praise_data):\n",
    "    quant_only = pd.DataFrame()\n",
    "    praise_data.drop(['DATE', 'TO USER ACCOUNT', 'TO ETH ADDRESS', 'FROM USER ACCOUNT', 'FROM ETH ADDRESS', 'REASON', 'SOURCE ID', 'SOURCE NAME', 'AVG SCORE', 'CORRECTION ADD', 'CORRECTION SUB', 'CORRECTION COMMENT','FINAL QUANT'], axis=1, inplace=True)\n",
    "    num_of_quants = int((praise_data.shape[1] -1)/ 4)\n",
    "    for i in range(num_of_quants):\n",
    "        q_name =  str( 'QUANTIFIER '+ str(i+1) +' USERNAME' )\n",
    "        q_addr =  str( 'QUANTIFIER '+ str(i+1) +' ETH ADDRESS')\n",
    "        q_value = str('SCORE '+str(i+1) )\n",
    "        buf = praise_data[['ID', q_name , q_addr, q_value ]].copy()\n",
    "    \n",
    "        buf.rename(columns={q_name: 'QUANT_ID', q_addr: 'QUANT_ADDRESS', q_value: 'QUANT_VALUE', 'ID':'PRAISE_ID'}, inplace=True)\n",
    "        #print(buf)\n",
    "        quant_only = quant_only.append(buf.copy(), ignore_index=True)\n",
    "\n",
    "    columnsTitles = ['QUANT_ID', 'QUANT_ADDRESS', 'PRAISE_ID', 'QUANT_VALUE']\n",
    "    quant_only.sort_values(['QUANT_ID', 'PRAISE_ID'], inplace=True)\n",
    "    quant_only =  quant_only.reindex(columns=columnsTitles).reset_index(drop=True)\n",
    "    return quant_only\n",
    "\n",
    "quantifier_rating_table = data_by_quantifier(praise_data.copy())\n",
    "quantifier_rating_table.style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83cc4d",
   "metadata": {},
   "source": [
    "Now, we will calculate the rewards for the Quantifiers and the Reward Board. This is fairly straightforward, since we distribute the allocated tokens equally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4677f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quantifier_rewards = pd.DataFrame(quantifier_rating_table[['QUANT_ID','QUANT_ADDRESS']].value_counts().reset_index().copy())\n",
    "quantifier_rewards.rename(columns={ quantifier_rewards.columns[2]: \"NUMBER_OF_PRAISES\" }, inplace = True)\n",
    "quantifier_rewards['TOKEN TO RECEIVE'] = NUMBER_OF_REWARD_TOKENS_FOR_QUANTIFIERS / len(quantifier_rewards.index)\n",
    "\n",
    "    \n",
    "quantifier_rewards.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7e71e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rewardboard_rewards = pd.DataFrame(rewardboard_addresses)\n",
    "rewardboard_rewards['TOKEN TO RECEIVE'] = NUMBER_OF_REWARD_TOKENS_FOR_REWARD_BOARD / len(rewardboard_rewards.index)\n",
    "rewardboard_rewards.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b78fa3",
   "metadata": {},
   "source": [
    "Now we can merge them all into one table and save it, ready for distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871efe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_total_data_chart(praise_rewards, sourcecred_rewards, quantifier_rewards, rewardboard_rewards):\n",
    "    \n",
    "    praise_rewards = praise_rewards.copy()[['USER IDENTITY', 'USER ADDRESS', 'TOKEN TO RECEIVE']].rename(columns = {'TOKEN TO RECEIVE':'PRAISE_REWARD'})\n",
    "    praise_rewards['USER ADDRESS'] = praise_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    sourcecred_rewards = sourcecred_rewards.copy()[['USER ADDRESS', 'TOKEN TO RECEIVE']].rename(columns = {'TOKEN TO RECEIVE':'SOURCECRED_REWARD'})\n",
    "    sourcecred_rewards['USER ADDRESS'] = sourcecred_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    quantifier_rewards.rename(columns = {'QUANT_ADDRESS':'USER ADDRESS', 'QUANT_ID': 'USER IDENTITY', 'TOKEN TO RECEIVE':'QUANT_REWARD'}, inplace = True)\n",
    "    quantifier_rewards['USER ADDRESS'] = quantifier_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    rewardboard_rewards.rename(columns = {'ID':'USER ADDRESS', 'TOKEN TO RECEIVE': 'REWARDBOARD_REWARD'}, inplace = True)\n",
    "    rewardboard_rewards['USER ADDRESS'] = rewardboard_rewards['USER ADDRESS'].str.lower()\n",
    "    \n",
    "    \n",
    "    final_allocations = pd.merge(rewardboard_rewards, quantifier_rewards , on=['USER ADDRESS','USER ADDRESS'], how='outer')\n",
    "    final_allocations = pd.merge(final_allocations , sourcecred_rewards, on=['USER ADDRESS','USER ADDRESS'],how='outer')\n",
    "    final_allocations = pd.merge(final_allocations, praise_rewards, left_on=['USER ADDRESS','USER IDENTITY'], right_on=['USER ADDRESS','USER IDENTITY'], how='outer')\n",
    "    \n",
    "    final_allocations['USER IDENTITY'].fillna('missing username', inplace = True)\n",
    "    final_allocations.fillna(0, inplace = True)\n",
    "    final_allocations['TOTAL TO RECEIVE'] = final_allocations['PRAISE_REWARD'] + final_allocations['SOURCECRED_REWARD'] + final_allocations['QUANT_REWARD'] + final_allocations['REWARDBOARD_REWARD']\n",
    "    \n",
    "    final_allocations = final_allocations.sort_values(by= 'TOTAL TO RECEIVE', ascending  = False).reset_index(drop=True)\n",
    "    return final_allocations\n",
    "\n",
    "final_token_allocations = prepare_total_data_chart(praise_by_user.copy(), processed_sourcecred.copy(), quantifier_rewards.copy(), rewardboard_rewards.copy())\n",
    "final_token_allocations.style\n",
    "\n",
    "#TODO: FIX COLUMN ORDER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-provider",
   "metadata": {},
   "source": [
    "# Results Analysis\n",
    "Let's dive into some data analysis! We'll use the metrics designed and explained by octopus🐙, and focus only on the praise rewards for now. Starting with:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-removal",
   "metadata": {},
   "source": [
    "### Allocation percentages\n",
    "This table will show us which percentage if the total rewards gets distributed to which top % of users. So \"Top 50% -> 0.85\" would mean that the top 50% of praisees received 85% of the total rewards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-leonard",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "p_vals = np.array([50,80,90,95,99])\n",
    "rewards_rp = np.array([tb.resource_percentage(praise_by_user[\"TOKEN TO RECEIVE\"], p) for p in p_vals])\n",
    "\n",
    "my_rd_index = [(\"Top \" + str(100 - p) +\"%\") for p in p_vals]\n",
    "resource_distribution = pd.DataFrame({\"Rewards\": rewards_rp}, index = my_rd_index)\n",
    "resource_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-observation",
   "metadata": {},
   "source": [
    "### Gini coefficient\n",
    "Next we will look at the Gini coefficient. Note that there is some debate if we want to use this metric at all, since it is usually employed to measure wealth distribution, and not compensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-sending",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "p_vals = np.array([0, 50, 80])\n",
    "rewards_gc = np.array([tb.gini_gt_p(np.array(praise_by_user[\"TOKEN TO RECEIVE\"]), p) for p in p_vals])\n",
    "\n",
    "my_index = [\"All\", \"Top 50%\", \"Top 20%\"]\n",
    "gini_coefs = pd.DataFrame({\"Rewards\": rewards_gc}, index = my_index)\n",
    "gini_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-research",
   "metadata": {},
   "source": [
    "### Shannon Entropy\n",
    "\n",
    "[Shannon Entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) is a concept from communications theory, which is also used in measuring the diversity of a distribution. The formula for calculating Shannon Entropy among $n$ individuals is\n",
    "    $$\\\\sum_{k=1}^n -p_k log_2(p_k),$$\n",
    "where $p_k$ represents the proportion of the resource that user $k$ received.\n",
    "\n",
    "Here we compare the actual Shannon Entropy with the maximum possible for the dataset, keeping in mind that a Shannon Entropy of 0 would mean one user holds all the rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-afternoon",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "entropies_df = pd.DataFrame(data = {\"Rewards\" : tb.calc_shannon_entropies(praise_by_user[\"PERCENTAGE\"]) }, index = [\"Entropy\", \"Max Entropy\", \"% of Max\"])\n",
    "entropies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-traffic",
   "metadata": {},
   "source": [
    "### Nakamoto Coefficient\n",
    "Last but not least, the Nakamoto coefficient. The Nakamato Coefficient is defined as the smallest number of accounts who control at least 50% of the resource. Although its significance relates to the prospect of a 51% attack on a network, which may not be relevant in our context, we can still use it as an intuitive measure of how many individuals received the majority of a resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-stock",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ak_coef_IH = tb.nakamoto_coeff(praise_by_user, \"PERCENTAGE\")\n",
    "ak_coef_IH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-peace",
   "metadata": {},
   "source": [
    "## Praise Data Visualization\n",
    "\n",
    "### Rating distribution\n",
    "Since praise gets valued on a scale, we can take a look at how often each value of the scale gets assigned by quantifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-services",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq = quantifier_rating_table[['QUANT_VALUE']].value_counts().rename_axis('QUANT_VALUE').reset_index(name='counts').sort_values(by=['QUANT_VALUE'])\n",
    "freq['QUANT_VALUE'] = freq['QUANT_VALUE'].astype('string')\n",
    "\n",
    "fig_freq = px.bar(freq, x=\"QUANT_VALUE\", y=\"counts\", labels={\"QUANT_VALUE\": \"Rating\",\"counts\": \"Number of appearances\"}, title=\"Praise Rating Distribution\", width=800, height=300)\n",
    "fig_freq.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-conspiracy",
   "metadata": {},
   "source": [
    "### Praise Reward Distribution\n",
    "\n",
    "We can also take a look at the distribution of the received praise rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-computer",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pr_distribution = praise_by_user[['USER IDENTITY', 'PERCENTAGE']].sort_values(by=['PERCENTAGE'], ascending=False)\n",
    "\n",
    "fig_pr_distribution = px.bar(pr_distribution, x='USER IDENTITY', y='PERCENTAGE', labels={\"IDENTITY\": \"User\",\"PERCENTAGE\": \"% of total\"}, title=\"Praise Reward Distribution\")#.opts(width=800, height=500, title='SourceCred Distribution', xlabel='Value', ylabel='% of Total', xaxis='bare')\n",
    "fig_pr_distribution.update_xaxes(showticklabels=False)\n",
    "\n",
    "fig_pr_distribution.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-drain",
   "metadata": {},
   "source": [
    "### Praise Flows\n",
    "\n",
    "Now for something more fun: let's surface the top \"praise flows\" from the data. Thanks to @inventandchill for this awesome visualization! \n",
    "On one side we have the top 20 praise givers separately (modifiable by changing the variable n_senders), on the other the top 25 receivers (modifiable by changing the variable n_receivers). The people outside the selection get aggregated into the \"REST FROM\" and \"REST TO\" categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-cleveland",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_SENDERS_FLOW = 15 #The left side, the praise senders. X largest ones + one bucket for the rest \n",
    "NUMBER_OF_RECEIVERS_FLOW = 25 #The right side, the praise receivers. X largest ones + one bucket for the rest \n",
    "dist_for_praise_flow = praise_distribution.rename(columns = {'FROM USER ACCOUNT':'FROM', 'TO USER ACCOUNT':'TO'})\n",
    "praise_flow = tb.prepare_praise_flow(dist_for_praise_flow.copy(), n_senders=NUMBER_OF_SENDERS_FLOW, n_receivers=NUMBER_OF_RECEIVERS_FLOW)\n",
    "#praise_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-veteran",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%opts Sankey (cmap='Category10' edge_color='FROM' edge_line_width=0 node_alpha=1.0)\n",
    "%%opts Sankey [node_sort=False label_position='outer' bgcolor=\"snow\" node_width=40 node_sort=True ]\n",
    "%%opts Sankey [width=1000 height=800 title=\"Praise flow for Batch 1. Sum of Praise. Left - praise sender. Right - praise receiver\"]\n",
    "%%opts Sankey [margin=0 padding=0 show_values=True]\n",
    "\n",
    "hv.Sankey(praise_flow, kdims=[\"FROM\", \"TO\"], vdims=[\"FINAL QUANT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-blond",
   "metadata": {},
   "source": [
    "## SourceCred Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-bread",
   "metadata": {},
   "source": [
    "### SourceCred token Distribution\n",
    "\n",
    "Next we can see the distribution made by the SourceCred algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-learning",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sc_distribution = processed_sourcecred[['USER ADDRESS', 'PERCENTAGE SOURCECRED']].sort_values(by=['PERCENTAGE SOURCECRED'], ascending=False)\n",
    "\n",
    "fig_sc_distribution = px.bar(sc_distribution, x='USER ADDRESS', y='PERCENTAGE SOURCECRED', labels={\"USER ADDRESS\": \"User\",\"PERCENTAGE SOURCECRED\": \"% of total\"}, title=\"SourceCred Distribution\")\n",
    "fig_sc_distribution.update_xaxes(showticklabels=False)\n",
    "\n",
    "fig_sc_distribution.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-retail",
   "metadata": {},
   "source": [
    "## Quantifier Data\n",
    "Let's take a closer look at each quantifier. In the following step we will use the raw praise data to zoom in on how each quantifier scored the praises:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-billion",
   "metadata": {},
   "source": [
    "### Amount of praise quantified\n",
    "With the above table we can easily see how much praise each quantifier rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-ranch",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig_pie = px.pie(quantifier_rewards, values='NUMBER_OF_PRAISES', names='QUANT_ID', title='Amount of praise per quantifier', labels={'NUMBER_OF_PRAISES': 'Praises quant'})\n",
    "fig_pie.update_layout(showlegend=False)\n",
    "fig_pie.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-narrative",
   "metadata": {},
   "source": [
    "## Total Token Distribution Visualization and  Export\n",
    "To send the allocations to the DAO for distribution, we need to put all data together and add the rewards for the reward board and the quantifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-cookie",
   "metadata": {},
   "source": [
    "Let's take a final look at the total distribution. Click on the legend to filter out specific reward sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-fountain",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig_final_alloc = px.bar(final_token_allocations, x=\"USER IDENTITY\", y = [\"QUANT_REWARD\", \"REWARDBOARD_REWARD\", \"PRAISE_REWARD\", \"SOURCECRED_REWARD\"], title=\"Rewards received by category\", color_discrete_map = {'PRAISE_REWARD': 'blue', 'SOURCECRED_REWARD': 'red', 'QUANT_REWARD':'green', 'REWARDBOARD_REWARD':'yellow'})\n",
    "fig_final_alloc.update_xaxes(showticklabels=False)\n",
    "fig_final_alloc.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-persian",
   "metadata": {},
   "source": [
    "That's it! We can now download the final distribution files and upload them to GitHub for future reference. We want to export 3 different files: <br>\n",
    "   &emsp;- The final reward allocations, separated by source<br>\n",
    "    &emsp;- The final reward allocations, in a disperse.app-readable format<br>\n",
    "   &emsp;- The extended praise data, detailing the how many tokens each single praise netted (for future reference)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-seventh",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_download_link(csv, filename, download_title):\n",
    "    filename = filename\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=download_title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "final_allocation_csv = final_token_allocations.to_csv(index=False)\n",
    "create_download_link(csv = final_allocation_csv, filename=OUTPUT_FILENAME, download_title = \"Download final reward CSV file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-tamil",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "final_alloc_disperse = final_token_allocations[['USER ADDRESS', 'TOTAL TO RECEIVE']].to_csv(sep=' ', index=False, header=False)\n",
    "create_download_link(final_alloc_disperse, filename=(OUTPUT_FILENAME+\"-disperse\"), download_title = \"Download disperse.app compatible file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-airfare",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "praise_reward_export = praise_distribution.to_csv(index=False)\n",
    "create_download_link(praise_reward_export, filename=OUTPUT_FILENAME+\"-extendedPraise\", download_title = \"Download complete praise data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21817365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
